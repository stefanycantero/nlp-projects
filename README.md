# üß† Natural Language Processing Projects ‚Äì Stefany Cantero

Este repositorio re√∫ne dos proyectos de **Procesamiento de Lenguaje Natural (PLN)** enfocados en el an√°lisis, clasificaci√≥n y modelado sem√°ntico de texto en espa√±ol.  
Ambos desarrollan pipelines de NLP end-to-end: desde la adquisici√≥n y limpieza de datos hasta el entrenamiento, evaluaci√≥n e interpretaci√≥n de modelos basados en machine learning y deep learning.

---

## üìÇ Estructura del repositorio
nlp-projects/
‚îú‚îÄ‚îÄ Sentiment_Analysis/
‚îÇ ‚îú‚îÄ‚îÄ data/
‚îÇ ‚îú‚îÄ‚îÄ notebooks/
‚îÇ ‚îú‚îÄ‚îÄ models/
‚îÇ ‚îî‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ News_Classification_Summarization/
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ models/
‚îî‚îÄ‚îÄ README.md

Cada carpeta incluye:
- `data/`: dataset original y preprocesado.  
- `notebooks/`: flujo completo de trabajo en Jupyter.  
- `models/`: modelos entrenados y m√©tricas de evaluaci√≥n.  
- `README.md`: descripci√≥n espec√≠fica del proyecto.
  
---
## Proyecto 1: An√°lisis de sentimientos en texto en espa√±ol  

**Librer√≠as:** `BeautifulSoup`, `Playwright`, `Scrapy`, `Pandas`, `NLTK`, `Scikit-learn`, `Matplotlib`, `Seaborn`

### Descripci√≥n
Proyecto enfocado en la detecci√≥n autom√°tica de sentimientos en textos en espa√±ol. Se construy√≥ un corpus de m√°s de **7,000 registros** mediante web scraping de foros y datasets de TASS, seguido de un proceso completo de **preprocesamiento ling√º√≠stico** (limpieza, tokenizaci√≥n, lematizaci√≥n, eliminaci√≥n de stopwords y construcci√≥n de n-gramas).

Se aplicaron t√©cnicas de **vectorizaci√≥n** con `CountVectorizer` y `TF-IDF`, y se entrenaron modelos de **clasificaci√≥n supervisada** (`Regresi√≥n Log√≠stica`, `√Årboles de Decisi√≥n`, `KNN`) para identificar la polaridad del texto.

### Flujo de trabajo
1. Extracci√≥n de datos v√≠a scraping (BeautifulSoup, Scrapy, Playwright).  
2. Limpieza, tokenizaci√≥n y normalizaci√≥n del texto.  
3. Representaci√≥n vectorial (TF-IDF y CountVectorizer).  
4. Entrenamiento de modelos con Scikit-learn.  
5. Evaluaci√≥n de m√©tricas (precision, recall, F1-score).  
6. Visualizaci√≥n de resultados con Seaborn y Matplotlib.

### Resultados
- Modelo seleccionado: **Regresi√≥n Log√≠stica con TF-IDF**  
- F1-score promedio: **84%**  
- Mayor estabilidad frente a desbalance de clases y vocabulario diverso.

---

## Proyecto 2: Clasificaci√≥n, resumen y an√°lisis tem√°tico de noticias  

**Librer√≠as:** `Transformers (DistilBERT, T5-small)`, `Gensim`, `spaCy`, `NLTK`, `Scikit-learn`, `PyLDAvis`, `Matplotlib`, `Pandas`

### üìò Descripci√≥n
Desarrollo de un sistema integral de **Procesamiento de Lenguaje Natural (PLN)** orientado a la **clasificaci√≥n, resumen autom√°tico y an√°lisis tem√°tico** de noticias en espa√±ol.

Incluye tres m√≥dulos principales:
1. **Clasificaci√≥n de texto** con modelo `DistilBERT-multilingual` (Hugging Face Transformers).  
2. **Generaci√≥n de res√∫menes autom√°ticos** con el modelo `T5-small`.  
3. **Modelado de temas** con `LDA (Latent Dirichlet Allocation)` implementado en Gensim.

El flujo combina t√©cnicas de *deep learning* y *topic modeling*, junto con visualizaci√≥n interactiva de resultados mediante `PyLDAvis`.

### ‚öôÔ∏è Flujo de trabajo
1. Preprocesamiento ling√º√≠stico con `spaCy` y `NLTK`.  
2. Fine-tuning y evaluaci√≥n del modelo `DistilBERT`.  
3. Generaci√≥n de res√∫menes autom√°ticos con `T5-small` y evaluaci√≥n con m√©tricas ROUGE.  
4. Modelado de temas con `LDA` y visualizaci√≥n con `PyLDAvis`.  
5. Integraci√≥n de m√≥dulos en un entorno interactivo mediante widgets en Jupyter Notebook.

### üìä Resultados
- **Clasificaci√≥n (DistilBERT):** F1-score = 80.16%  
- **Resumen autom√°tico (T5-small):** coherencia sem√°ntica validada con ROUGE.  
- **Modelado de temas (LDA):** coherencia ‚âà 46%, visualizaci√≥n clara de t√≥picos predominantes.

